{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a959d3-8abb-41a5-9233-5b92402bc227",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a727049-967c-494e-98f5-7128fdc6e5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_averaged_file_path = \"/nsls2/data/projects/ldrd-22-031-blopt/raw_averaged.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a233db7b-798e-4dea-97df-8fd8df4b6773",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time raw_avg_images = np.load(raw_averaged_file_path).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5b6af0-b7f1-4a13-925b-e560bf83e6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"raw_avg_images.shape: {raw_avg_images.shape}\")\n",
    "raw_avg_images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476e44ff-143f-41c0-938b-0acaebfacf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189b7645-6b79-4f25-b85f-c1128686cb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=1, ncols=3)\n",
    "axs[0].imshow(raw_avg_images[0, :, :])\n",
    "axs[0].set_title(\"raw averaged image 0\")\n",
    "axs[1].hist(raw_avg_images[0, :, :].flatten(), log=True, bins=20)\n",
    "axs[2].hist(raw_avg_images[::100].flatten(), bins=20, log=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ca4536-ce07-4dfd-9409-05f5b4ff7a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd4d6a6-3edc-41f2-ad36-887b7ac06992",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054260a1-4d3e-42d7-b863-25d4d0bc4a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_raw_avg_images = np.zeros((raw_avg_images.shape[0], 16, 16))\n",
    "for i in range(resized_raw_avg_images.shape[0]):\n",
    "    resized_raw_avg_images[i, :, :] = cv2.resize(raw_avg_images[i, :, :], resized_raw_avg_images.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57624ac9-7bcd-4265-80ee-6fd65a019cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=1, ncols=3)\n",
    "axs[0].imshow(raw_avg_images[0])\n",
    "axs[0].set_title(\"raw averaged image 0\")\n",
    "axs[1].imshow(resized_raw_avg_images[0])\n",
    "axs[2].hist(resized_raw_avg_images.flatten(), log=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395ff4af-d273-4fa0-a640-8ef006e853b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eaafe9c-d429-475a-840a-1b10e84b3af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa26310-af09-444c-9648-647d168d9819",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417bfd14-6863-4cee-bce8-15ff2dee0025",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_beamline_model(parameter_count):\n",
    "    # take four parameters and expand them to a larger layer\n",
    "    beamline_middle = nn.Sequential(\n",
    "        nn.Linear(parameter_count, 8),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(8, 64),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(64, 256),  # for 16x16 filter\n",
    "        # nn.ReLU()\n",
    "    )\n",
    "    beamline_up = nn.Sequential(\n",
    "        nn.Conv2d(\n",
    "            in_channels=1,\n",
    "            out_channels=8,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1\n",
    "        ),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(\n",
    "            in_channels=8,\n",
    "            out_channels=16,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1\n",
    "        ),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(\n",
    "            in_channels=16,\n",
    "            out_channels=32,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1\n",
    "        ),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(\n",
    "            in_channels=32,\n",
    "            out_channels=16,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1\n",
    "        ),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(\n",
    "            in_channels=16,\n",
    "            out_channels=8,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1\n",
    "        ),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(\n",
    "            in_channels=8,\n",
    "            out_channels=1,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    class BL(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "\n",
    "            self.beamline_middle = beamline_middle\n",
    "            self.beamline_up = beamline_up\n",
    "\n",
    "        def forward(self, beamline_parameters):\n",
    "            batch_count = beamline_parameters.shape[0]\n",
    "\n",
    "            beamline_parameters_embedding = self.beamline_middle(beamline_parameters)\n",
    "\n",
    "            beamline_parameters_embedding_2d = beamline_parameters_embedding.reshape(batch_count, -1, 16, 16)\n",
    "            \n",
    "            image = self.beamline_up(beamline_parameters_embedding_2d)\n",
    "\n",
    "            return image\n",
    "    \n",
    "    return BL()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f300b95-e015-4d68-b737-40c8d09c2488",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_m = build_beamline_model(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ec1f80-bd1f-4ee8-85eb-46b284f3771d",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(\n",
    "    b_m, \n",
    "    input_data=torch.ones(2, 1, 4),\n",
    "    col_names=(\"input_size\", \"output_size\", \"num_params\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06547ec8-bc73-4675-a6c5-cabb2e2280c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from databroker import Broker\n",
    "db = Broker.named(\"tes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319e7c40-2b94-48e3-be63-fa73e8efe9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_beamline_parameters(db):\n",
    "    hdr = db[9585]\n",
    "    the_data = hdr.table()\n",
    "    the_parameters = the_data[['kbh_ush','kbh_dsh','kbv_ush','kbv_dsh']]\n",
    "    return the_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55db42ea-a5b3-46b7-b214-d9a3b1faa855",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time beamline_parameters = np.array(get_beamline_parameters(db), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71998486-dd8a-4f2b-a01d-bae6df04df5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"beamline_parameters.shape: {beamline_parameters.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c04277-e5da-4b3e-b343-320d58f881fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a class to interact with DataLoaders\n",
    "class BeamlineDataset:\n",
    "    def __init__(self, beamline_parameters, beam_images):\n",
    "        \"\"\"\n",
    "          beamline_parameters  samples x 4       (4 motor positions)\n",
    "          beam_images          samples x 16 x 16\n",
    "        \"\"\"\n",
    "        self.beamline_parameters = np.array(beamline_parameters, dtype=np.float32)\n",
    "        # expand the dimensions of beam_images to include a \"channel\" dimension\n",
    "        self.beam_images = np.expand_dims(np.array(beam_images, dtype=np.float32), axis=1)\n",
    "        self.beam_images_brightest_pixel = np.argmax(beam_images)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.beamline_parameters[index], self.beam_images[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.beamline_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c99cdb2-5596-4952-9428-8c7eff14d6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_beamline_dataset(beamline_parameters, beam_images, training_sample_count, testing_sample_count):\n",
    "    shuffled_full_int_index = np.array(\n",
    "        list(\n",
    "            range(training_sample_count + testing_sample_count)\n",
    "        ),\n",
    "        dtype=int\n",
    "    )\n",
    "    np.random.shuffle(shuffled_full_int_index)\n",
    "\n",
    "    training_int_index = shuffled_full_int_index[:training_sample_count]\n",
    "    testing_int_index = shuffled_full_int_index[training_sample_count:training_sample_count+testing_sample_count]\n",
    "    \n",
    "    training_beamline_parameters = beamline_parameters[training_int_index]\n",
    "    training_beam_images = beam_images[training_int_index]\n",
    "    \n",
    "    testing_beamline_parameters = beamline_parameters[testing_int_index]\n",
    "    testing_beam_images = beam_images[testing_int_index]\n",
    "\n",
    "    training_beamline_dataset = BeamlineDataset(\n",
    "        beamline_parameters=training_beamline_parameters,\n",
    "        beam_images=training_beam_images\n",
    "    )\n",
    "\n",
    "    print(f\"len(training_beamline_dataset): {len(training_beamline_dataset)}\")\n",
    "    training_beamline_parameters_sample, training_beam_images_sample = training_beamline_dataset[1]\n",
    "    print(f\"training_beamline_parameters_sample.shape : {training_beamline_parameters_sample.shape}\")\n",
    "    print(f\"training_beamline_parameters_sample.dtype : {training_beamline_parameters_sample.dtype}\")\n",
    "    print(f\"training_beam_images_sample.shape : {training_beam_images_sample.shape}\")\n",
    "    print(f\"training_beam_images_sample.dtype : {training_beam_images_sample.dtype}\")\n",
    "    \n",
    "    testing_beamline_dataset = BeamlineDataset(\n",
    "        beamline_parameters=testing_beamline_parameters,\n",
    "        beam_images=testing_beam_images\n",
    "    )\n",
    "    \n",
    "    return training_beamline_dataset, testing_beamline_dataset\n",
    "\n",
    "build_beamline_dataset(\n",
    "    beamline_parameters=beamline_parameters,\n",
    "    beam_images=resized_raw_avg_images,\n",
    "    training_sample_count=10,\n",
    "    testing_sample_count=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbba435-c23c-4ac7-b548-3c212daea10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    beamline_model,\n",
    "    optimizer,\n",
    "    loss_function,\n",
    "    train_dataloader,\n",
    "    test_dataloader,\n",
    "    epoch_count\n",
    "):\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "\n",
    "    beamline_model.to(device)\n",
    "\n",
    "    for epoch_i in range(epoch_count):\n",
    "        training_loss = 0.0\n",
    "        beamline_model.train()\n",
    "        #for correct_squashed_circle_images, (circle_images, radius_scale_factors) in train_dataloader:\n",
    "        for beamline_parameters, correct_beam_images in train_dataloader:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # torch calls circle_images 'inputs'\n",
    "            correct_beam_images = correct_beam_images.to(device)\n",
    "            #correct_squashed_circle_images = correct_squashed_circle_images.to(device)\n",
    "            beamline_parameters = beamline_parameters.to(device)\n",
    "            \n",
    "            predicted_beam_images = beamline_model(\n",
    "                beamline_parameters\n",
    "            )\n",
    "\n",
    "            loss = loss_function(\n",
    "                predicted_beam_images,\n",
    "                correct_beam_images\n",
    "            )\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            training_loss += loss.data.item()\n",
    "\n",
    "        training_loss /= len(train_dataloader.dataset)\n",
    "\n",
    "        test_loss = 0.0\n",
    "        beamline_model.eval()\n",
    "        for beamline_parameters, correct_beam_images in test_dataloader:\n",
    "\n",
    "            # torch calls circle_images 'inputs'\n",
    "            #circle_images = circle_images.to(device)\n",
    "            correct_beam_images = correct_beam_images.to(device)\n",
    "            beamline_parameters = beamline_parameters.to(device)\n",
    "\n",
    "            predicted_beam_images = beamline_model(\n",
    "                beamline_parameters\n",
    "            )\n",
    "\n",
    "            loss = loss_function(\n",
    "                predicted_beam_images,\n",
    "                correct_beam_images\n",
    "            )\n",
    "            test_loss += loss.data.item()\n",
    "\n",
    "        test_loss /= len(test_dataloader.dataset)\n",
    "\n",
    "        print(\n",
    "            f\"Epoch: {epoch_i}, Training Loss: {training_loss:.5f}, Test Loss: {test_loss:.5f}\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850aeeff-8096-49c0-ab8a-859da6ee1730",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset, testing_dataset = build_beamline_dataset(\n",
    "    beamline_parameters=beamline_parameters,\n",
    "    beam_images=resized_raw_avg_images,\n",
    "    training_sample_count=40000,\n",
    "    testing_sample_count=10000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc74ae9-a3e1-4c3f-90e3-c57fc6bc01fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "training_beamline_dataloader = DataLoader(\n",
    "    training_dataset,\n",
    "    batch_size=100,  # one batch must fit in the GPU memory\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "testing_beamline_dataloader = DataLoader(\n",
    "    testing_dataset,\n",
    "    batch_size=10\n",
    ")\n",
    "\n",
    "beamline_model = build_beamline_model(parameter_count=4)\n",
    "train(\n",
    "    beamline_model,\n",
    "    torch.optim.Adam(beamline_model.parameters()),\n",
    "    torch.nn.MSELoss(),\n",
    "    training_beamline_dataloader,\n",
    "    testing_beamline_dataloader,\n",
    "    epoch_count=500\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519c65bb-5bf0-418b-9a37-3e296ce2ed33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the range of each beamline parameter\n",
    "beamline_parameter_mins = np.amin(beamline_parameters, axis=0)\n",
    "beamline_parameter_maxs = np.amax(beamline_parameters, axis=0)\n",
    "\n",
    "print(f\"beamline parameter mins: {beamline_parameter_mins}\")\n",
    "print(f\"beamline parameter maxs: {beamline_parameter_maxs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052f0780-4afd-4a87-a280-5546946b1f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_beam(beamline_model, beamline_parameters, kbh_ush, kbh_dsh, kbv_ush, kbv_dsh):\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "\n",
    "    beamline_model.to(device)\n",
    "\n",
    "    beamline_model.eval()\n",
    "\n",
    "    beamline_parameters_for_prediction = np.array(\n",
    "        [[kbh_ush, kbh_dsh, kbv_ush, kbv_dsh],],\n",
    "    )\n",
    "    print(f\"beamline_parameters_for_prediction.shape: {beamline_parameters_for_prediction.shape}\")\n",
    "\n",
    "    # find the nearest real image\n",
    "    m = np.sum(np.square(beamline_parameters_for_prediction - beamline_parameters))\n",
    "    m_argmin = np.argmin(m)\n",
    "    \n",
    "    nearest_beamline_parameters = beamline_parameters[m_argmin, :]\n",
    "    print(f\"nearest beamline parameters: {nearest_beamline_parameters}\")\n",
    "    \n",
    "    #beamline_parameters = beamline_parameters.to(device)\n",
    "    predicted_beam_image = beamline_model(torch.Tensor(beamline_parameters_for_prediction)).detach().numpy()\n",
    "    \n",
    "    fig, axs = plt.subplots(nrows=1, ncols=4)\n",
    "    axs[0].imshow(predicted_beam_image[0, 0, :, :])\n",
    "    axs[0].set_title(\"predicted\\nbeam\\nimage\")\n",
    "    axs[1].hist(predicted_beam_image.flatten())\n",
    "    axs[2].imshow(resized_raw_avg_images[m_argmin])\n",
    "    axs[3].hist(resized_raw_avg_images[m_argmin].flatten())\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b277ba4-5b47-46cb-b6f1-f45b351834d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_beam(beamline_model, beamline_parameters, 2.21212, 3.41414, 2.61616, 4.31313)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123c0b66-2e33-4a90-a893-81adde0d5115",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(raw_avg_images[:3, :, :], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8395e9-8fd4-4ade-a835-4fe02443e27b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
